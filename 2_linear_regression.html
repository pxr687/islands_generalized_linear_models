
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Linear Regression &#8212; Islands - Generalized Linear Models</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2_linear_regression';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Poisson Regression" href="3_poisson_regression.html" />
    <link rel="prev" title="What are Generalized Linear Models?" href="1_generalized_linear_models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="None">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="0_main_page.html">

  
  
  
  
  
  
  

  
    <img src="_static/islands_main.png" class="logo__image only-light" alt="Logo image">
    <img src="_static/islands_main.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="1_generalized_linear_models.html">
                        What are Generalized Linear Models?
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Linear Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="3_poisson_regression.html">
                        Poisson Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="4_binary_logistic_regression.html">
                        Binary Logistic Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="5_multinomial_logistic_regression.html">
                        Multinomial Logistic Regression
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="99_about_the_author.html">
                        About the author
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="1_generalized_linear_models.html">
                        What are Generalized Linear Models?
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Linear Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="3_poisson_regression.html">
                        Poisson Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="4_binary_logistic_regression.html">
                        Binary Logistic Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="5_multinomial_logistic_regression.html">
                        Multinomial Logistic Regression
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="99_about_the_author.html">
                        About the author
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="0_main_page.html">

  
  
  
  
  
  
  

  
    <img src="_static/islands_main.png" class="logo__image only-light" alt="Logo image">
    <img src="_static/islands_main.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0_main_page.html">
                    Who this book is for
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1_generalized_linear_models.html">What are Generalized Linear Models?</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_poisson_regression.html">Poisson Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_binary_logistic_regression.html">Binary Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="5_multinomial_logistic_regression.html">Multinomial Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="99_about_the_author.html">About the author</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">


<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
  </ul>
</div>

<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F2_linear_regression.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="_sources/2_linear_regression.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Linear Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#context">
   Context
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model">
   Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameter-estimation">
   Parameter Estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementation">
   Implementation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretation-one-predictor-model">
   Interpretation (one predictor model)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression-with-multiple-predictors">
   Linear Regression with multiple predictors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretation-multiple-predictors">
   Interpretation (multiple predictors)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#statistical-interaction-in-linear-regression">
   Statistical interaction in Linear Regression
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section class="tex2jax_ignore mathjax_ignore" id="linear-regression">
<h1>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">#</a></h1>
<br>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/island_lin_reg.png"><img alt="_images/island_lin_reg.png" class="bg-primary mb-1 align-center" src="_images/island_lin_reg.png" style="width: 270px;" /></a>
<br><p>Imagine you are conducting social research on an island with 10,000 people living on it. Imagine further that the citizens of the island use a set of physical credits to represent social status. That is, the amount of social status (or lack thereof) that each islander has is represented in the number of ‘prestige credits’ that they have in their possession. The prestige credits are awarded by those around them, and by the government of the island.</p>
<p>One of the social scientists in your research team suggests that citizens of the islands who are wealthier attract a higher number of prestige credits. The statistical version of this hypothesis is that <code class="docutils literal notranslate"><span class="pre">prestige</span></code> is postiviely associated with <code class="docutils literal notranslate"><span class="pre">wealth</span></code>. One way of thinking about this statistical hypothesis is that, if you know an islander’s <code class="docutils literal notranslate"><span class="pre">wealth</span></code>, then this gives you predictive information about their social status. If you know someone is far above average <code class="docutils literal notranslate"><span class="pre">wealth</span></code>, then, if the hypothesis is true, then it’s a safe bet that also have above average <code class="docutils literal notranslate"><span class="pre">prestige</span></code>.</p>
<p>To test this hypothesis, your research team collect <code class="docutils literal notranslate"><span class="pre">wealth</span></code> and <code class="docutils literal notranslate"><span class="pre">prestige</span></code> scores for 1000 citizens of the island. You do this via random sampling. The government of the island has granted the research team access to census data, and so your team were able to use a computer to randomly select 1000 individuals, and survey them to collect the data.</p>
<p>The team contacted the 1000 randomly sampled islanders and asked them to complete a survey recording their <code class="docutils literal notranslate"><span class="pre">wealth</span></code> and <code class="docutils literal notranslate"><span class="pre">prestige</span></code>. The first 20 rows of the dataframe in which the team stored the <code class="docutils literal notranslate"><span class="pre">prestige</span></code> scores are shown below (each row corresponds to one islander). The variables contained in the dataframe are detailed below:</p>
<p><code class="docutils literal notranslate"><span class="pre">prestige</span></code> - a discrete numerical variable, the number of prestige credits each islander has.</p>
<p><code class="docutils literal notranslate"><span class="pre">wealth</span></code> - a continuous numerical variable, recorded in units of the currency of the island.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># importing some python packages needed for this page</span>
<span class="kn">import</span> <span class="nn">islands_GLM</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>

<span class="c1"># generating the data for this page</span>
<span class="n">wealth_pop</span><span class="p">,</span> <span class="n">religion_pop</span><span class="p">,</span> <span class="n">prestige_pop</span><span class="p">,</span> <span class="n">df</span> <span class="o">=</span> <span class="n">islands_GLM</span><span class="o">.</span><span class="n">prestige_wealth_df</span><span class="p">()</span>

<span class="c1"># making plots look like R!</span>
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">r_ify</span><span class="p">()</span>

<span class="c1"># show the data</span>
<span class="n">df</span><span class="p">[[</span><span class="s1">&#39;wealth&#39;</span><span class="p">,</span> <span class="s1">&#39;prestige&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>wealth</th>
      <th>prestige</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>181.35</td>
      <td>641</td>
    </tr>
    <tr>
      <th>1</th>
      <td>178.62</td>
      <td>652</td>
    </tr>
    <tr>
      <th>2</th>
      <td>176.06</td>
      <td>689</td>
    </tr>
    <tr>
      <th>3</th>
      <td>190.41</td>
      <td>632</td>
    </tr>
    <tr>
      <th>4</th>
      <td>166.84</td>
      <td>635</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>995</th>
      <td>168.00</td>
      <td>558</td>
    </tr>
    <tr>
      <th>996</th>
      <td>165.21</td>
      <td>544</td>
    </tr>
    <tr>
      <th>997</th>
      <td>139.76</td>
      <td>519</td>
    </tr>
    <tr>
      <th>998</th>
      <td>168.80</td>
      <td>525</td>
    </tr>
    <tr>
      <th>999</th>
      <td>172.47</td>
      <td>692</td>
    </tr>
  </tbody>
</table>
<p>1000 rows × 2 columns</p>
</div></div></div>
</div>
<p>From inspecting the scatterplot of <code class="docutils literal notranslate"><span class="pre">wealth</span></code> against <code class="docutils literal notranslate"><span class="pre">prestige</span></code> (shown below), your team decide the trend looks roughly linear, and so decide to fit a linear regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code generates the plot below</span>
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">plot_prestige_wealth</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;wealth&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;prestige&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/bffce22c67a61881b2a884f98549188941b5fdcb5190c64f6387c248e44cec6c.png" src="_images/bffce22c67a61881b2a884f98549188941b5fdcb5190c64f6387c248e44cec6c.png" />
</div>
</div>
<section id="context">
<h2>Context<a class="headerlink" href="#context" title="Permalink to this headline">#</a></h2>
<p>Linear regression is (somewhat obviously) the foundational generalized linear model. We have already seen it on the <a class="reference internal" href="1_generalized_linear_models.html"><span class="doc std std-doc">‘What are Generalized Linear Models?’</span></a> page, but now we will delve into how the parameter estimates are obtained, via the conditional distribution (aka maximum likelihood) approach.</p>
<p>Linear regression is used to model the linear relationship between a quantitative outcome variable and one or more predictor variables. As with all generalized linear models, the predictor variables can be of any type (quantitative-continuous, quantitative-discrete, nominal-categorical, ordinal-categorical).</p>
<p>The predictions from linear regression can range from positive infinity to negative infinity. So if the outcome variable is does not (theoreticall) range from positive to negative infinity, for instance if it must be positive (e.g. number of children), then the model may produce nonsensical predictions. In this case, the outcome variable <code class="docutils literal notranslate"><span class="pre">prestige</span></code> is  quantitative, and judging from the scatterplot, has a mean far from 0. If the mean were close to 0, we might consider fitting a different generalized linear model, as negative predictions may not make sense for <code class="docutils literal notranslate"><span class="pre">prestige</span></code>.</p>
</section>
<section id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline">#</a></h2>
<p>As shown previously, the prediction equation for the linear regression model is:</p>
<p><span class="math notranslate nohighlight">\(\large \hat{y}_i = b_0 + b_1x_{1i} + ... + b_kx_{ki} \)</span></p>
<p>…where there are <span class="math notranslate nohighlight">\(k\)</span> predictor variables, and <span class="math notranslate nohighlight">\(n\)</span> observations, where an individual observation is denoted with <span class="math notranslate nohighlight">\(i\)</span>, and where:</p>
<p><span class="math notranslate nohighlight">\(\hat{y_i} \)</span> : is the predicted value of the outcome variable for a given set of predictor scores, for the <span class="math notranslate nohighlight">\(i\)</span>th observation</p>
<p><span class="math notranslate nohighlight">\(b_0\)</span> : is the intercept term, the predicted value of the outcome variable when all predictors equal 0</p>
<p><span class="math notranslate nohighlight">\(b_1\)</span> : is the slope of the 1st predictor variable</p>
<p><span class="math notranslate nohighlight">\(x_{1i}\)</span> : is the score on the the first predictor variable, for the <span class="math notranslate nohighlight">\(i\)</span>th observation</p>
<p><span class="math notranslate nohighlight">\(b_k\)</span> : is the slope of the <span class="math notranslate nohighlight">\(k\)</span>th predictor variable</p>
<p><span class="math notranslate nohighlight">\(x_{ki}\)</span> : is the score on the <span class="math notranslate nohighlight">\(k\)</span>th predictor variable, for the <span class="math notranslate nohighlight">\(i\)</span>th observation</p>
<p>The individual predictions (<span class="math notranslate nohighlight">\(\hat{y_i}\)</span>), for all <span class="math notranslate nohighlight">\(n\)</span> observations, using <span class="math notranslate nohighlight">\(k\)</span> variables as predictors are:</p>
<div class="math notranslate nohighlight">
\[ \large \hat{y}_1 = b_{0} + b_{1}x1_1 + \dots + b_{k}xk_1 \]</div>
<div class="math notranslate nohighlight">
\[ \large \hat{y}_2 = b_{0} + b_{1}x1_2 + \dots + b_{k}xk_2 \]</div>
<div class="math notranslate nohighlight">
\[ \large \hat{y}_3 = b_{0} + b_{1}x1_3 + \dots + b_{k}xk_3  \]</div>
<div class="math notranslate nohighlight">
\[ \dots \]</div>
<div class="math notranslate nohighlight">
\[ \large \hat{y}_n = b_{0} + b_{1}x1_n + \dots + b_{k}xk_n  \]</div>
<p><span class="math notranslate nohighlight">\(\hat{y}_1\)</span> is the predicted score on the outcome variable for the 1st observation in the dataset,  <span class="math notranslate nohighlight">\(\hat{y}_2\)</span> is the prediction for the second score and so on…</p>
<p>For each predictor (<span class="math notranslate nohighlight">\(x_k\)</span>), each <span class="math notranslate nohighlight">\(b_{k}\)</span> indicates the strength and direction of the relationship between that predictor <span class="math notranslate nohighlight">\(xk\)</span> and the outcome variable <span class="math notranslate nohighlight">\(y\)</span>. If the absolute magnitude of <span class="math notranslate nohighlight">\(b_{k}\)</span> is large, then that predictor gives a lot of information about the outcome scores, and is a useful predictor. If <span class="math notranslate nohighlight">\(b_{k}\)</span> is small, the predictor does not give much information about the outcome scores.</p>
<p><span class="math notranslate nohighlight">\(b_0\)</span> indicates the predicted score on the outcome variable for an obervation with a score of 0 on all the predictors (where the predictor is categorical, the prediction is for an observation in the baseline category).</p>
<p>In matrix form the linear regression model is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\Large \begin{bmatrix}
           {\hat{y}_{1}} \\
           \vdots \\
           {\hat{y}_{n}}
         \end{bmatrix} = \begin{bmatrix}
           {1} &amp; {x_{11}} &amp; \dots &amp; {x_{k1}}\\ 
           \vdots &amp; \vdots &amp; \vdots &amp; \vdots\\
           {1} &amp; {x_{1n}} &amp; \dots &amp; {x_{kn}} \\ 
         \end{bmatrix} \begin{bmatrix}
           {b_{0}} \\ 
           \vdots \\
           {b_{k}} \\ 
         \end{bmatrix} 
\end{split}\]</div>
<p>Or, more compactly:</p>
<p><span class="math notranslate nohighlight">\( \large \hat{Y} = \beta X\)</span></p>
<p>where <span class="math notranslate nohighlight">\(\hat{Y}\)</span> is a vector containing the predicted outcome scores. <span class="math notranslate nohighlight">\(\beta\)</span> is a vector containing the parameter estimates (the intercept and slopes) and  <span class="math notranslate nohighlight">\(X\)</span> is a matrix containing the predictor scores and a column of 1s (as shown above).</p>
<p>For the data that your research term have collected on the island, the linear regression model predicting <code class="docutils literal notranslate"><span class="pre">prestige</span></code> from <code class="docutils literal notranslate"><span class="pre">wealth</span></code> is:</p>
<p><span class="math notranslate nohighlight">\(\large \hat{\text{prestige}}_i = b_0 + b_1\text{wealth}_{i} \)</span></p>
</section>
<section id="parameter-estimation">
<h2>Parameter Estimation<a class="headerlink" href="#parameter-estimation" title="Permalink to this headline">#</a></h2>
<p>The model gets its parameters, by maximizing the likelihood function, the formula for which is:</p>
<p><span class="math notranslate nohighlight">\(  \huge \prod\limits_{i = 1}^{n} \left(\frac{1}{(2\pi\sigma^{2})^{^{\frac{1}{2}}}}\right)^n e^{\frac{-\sum{(y_{i} - \hat{y_{i}})^{2}}}{2\sigma^{2}}}  \)</span></p>
<p>If you don’t recognize that formula it might look formidable. It is in fact a version of the probability density function for the famous Gaussian (normal) distribution. The mean of the normal distribution is <span class="math notranslate nohighlight">\(\hat{y_i}\)</span> and the variance is <span class="math notranslate nohighlight">\(\sigma\)</span>. For a given value of <span class="math notranslate nohighlight">\(\hat{y_i}\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, the likelihood function computes the probability of randomly sampling a particular observation <span class="math notranslate nohighlight">\(y_i\)</span> from a normal distribution with that particular mean and variance ( <span class="math notranslate nohighlight">\(\hat{y_i}\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>).</p>
<p>Essentially, this formula translates as “let’s assume each observation is sampled from a normal distribution with a given mean and variance. We use the linear prediction equation to model the mean of the normal distribution from which each observation was sampled. We find the intercept and slope values such that the means of the normal distributions are closer to the datapoints than for any other line”. That is a lot to get your head around, so consider it in the context of this image:</p>
<p><img alt="" src="_images/GLM_normal_identity.png" /></p>
<p>(Image from: <a class="reference external" href="https://blogs.sas.com/content/iml/2015/09/10/plot-distrib-reg-model.html">https://blogs.sas.com/content/iml/2015/09/10/plot-distrib-reg-model.html</a>)</p>
<p>The python cell below defines a function which implements the probability density function of the normal distribution, on a given set of <span class="math notranslate nohighlight">\(y\)</span> values, and for a normal distribution with a particular mean (<span class="math notranslate nohighlight">\(\hat{y}\)</span>) and standard deviation (<span class="math notranslate nohighlight">\(\sigma\)</span>). This is very similar to the likelihood formula shown above, only it returns a vector of probabilities, rather than the product of the probabilities. Each element of the vector returned by the function is the probability of randomly sampling each of the <span class="math notranslate nohighlight">\(y\)</span> values from a normal distribution with the specified mean (<span class="math notranslate nohighlight">\(\hat{y}\)</span>) and standard deviation (<span class="math notranslate nohighlight">\(\sigma\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># defining a function which implements the probability density function of the normal distribution</span>
<span class="k">def</span> <span class="nf">normal_pdf</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
  
      <span class="n">output</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">e</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

      <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<p>The python cell below applies this function to each element of a vector containing integers ranging from -15 to 15, and plots the results. The y-axis shows the probability of getting each of those scores, if randomly sampling from a normal distribution with a mean of 0 and a standard deviation of 5:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot a normal distribution, using the function defined above</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span>
<span class="n">prob</span> <span class="o">=</span> <span class="n">normal_pdf</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">prob</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$\hat</span><span class="si">{y_i}</span><span class="s2"> = 0 $ and $\sigma = 5$&quot;</span><span class="p">)</span> 
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">normal_labels</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5ccdc70a2fcfc3f59d9326c62ab96afec1d3c10c7f49e4d586e373c9e2a551d8.png" src="_images/5ccdc70a2fcfc3f59d9326c62ab96afec1d3c10c7f49e4d586e373c9e2a551d8.png" />
</div>
</div>
<p>We can see that randomly sampling scores around the mean is more probable than scores in the tails of the distribution, far from the mean.</p>
<p>The cell below re-runs the function, and this time also shows the probability of obtaining each score ranging from -15 to 15 if randomly sampling from a normal distribution with  mean of -5 and a variance of 5 (this graph is shown in blue):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># also plot a normal distribution with different parameters</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span>
<span class="n">prob</span> <span class="o">=</span> <span class="n">normal_pdf</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">prob</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$\hat</span><span class="si">{y_i}</span><span class="s2"> = 0 $ and $\sigma = 5$&quot;</span><span class="p">)</span> 
<span class="n">prob</span> <span class="o">=</span> <span class="n">normal_pdf</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">prob</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$\hat</span><span class="si">{y_i}</span><span class="s2"> = -5 $ and $\sigma = 5$&quot;</span><span class="p">)</span> 
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">normal_labels</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4bb30a34d6e5add3626d1ef47aab2b6ec3affe291cd021ef6234f41f8f9cf750.png" src="_images/4bb30a34d6e5add3626d1ef47aab2b6ec3affe291cd021ef6234f41f8f9cf750.png" />
</div>
</div>
<p>We can see that as we vary the parameters (<span class="math notranslate nohighlight">\(\hat{y_i}\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>) the probability of getting a given score changes. Scores closer to -5 are more probable if sampling from a normal distribution with a mean of -5, than if randomly sampling from a normal distribution with a mean of 0.</p>
<p>The graph below shows the effect of applying this functon, with a variety of different <span class="math notranslate nohighlight">\(\hat{y_i}\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> pairings:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code generates the plot below</span>
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">normal_plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/642af1af5ef66dd52b158dc6163804dbe329269ed4356d030bd6d84864e4f287.png" src="_images/642af1af5ef66dd52b158dc6163804dbe329269ed4356d030bd6d84864e4f287.png" />
</div>
</div>
<p>As we saw on the <a class="reference internal" href="1_generalized_linear_models.html"><span class="doc std std-doc">‘What are Generalized Linear Models?’</span></a> page, linear regression involves fitting a set of conditional normal distributions to the outcome data, as a function of the predictor variables. This is shown again in the image below:</p>
<p><img alt="" src="_images/GLM_normal_identity.png" /></p>
<p>(Image from: <a class="reference external" href="https://blogs.sas.com/content/iml/2015/09/10/plot-distrib-reg-model.html">https://blogs.sas.com/content/iml/2015/09/10/plot-distrib-reg-model.html</a>)</p>
<p>The likelihood function shown above fits these conditional normal distributions to the data. The likelihood function allows the mean (<span class="math notranslate nohighlight">\(\hat{y}_i\)</span>) of each normal distribution to vary as a function of the predictor variables (<span class="math notranslate nohighlight">\(\hat{y}_i = b_0 + b_1x_{1i} ... + b_kx_{ki})\)</span>. The function takes the dataset (the predictor scores and outcome scores), and two parameters (<span class="math notranslate nohighlight">\(\hat{y_i}\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>) and computes the likelihood of obtaining the outcome scores, conditional on the predictor scores and those particular parameters. (NB: <span class="math notranslate nohighlight">\(\hat{y_i}\)</span> is a vector containing each of the predictions from the linear prediction equation, for a given intercept/slope set).</p>
<p>By finding the values of of <span class="math notranslate nohighlight">\(b_0\)</span>,  <span class="math notranslate nohighlight">\(b_k\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> which maximize the likelihood function (e.g. values of of <span class="math notranslate nohighlight">\(b_0\)</span>,  <span class="math notranslate nohighlight">\(b_k\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> which yield a higher value of the function than any other values of of <span class="math notranslate nohighlight">\(b_0\)</span>,  <span class="math notranslate nohighlight">\(b_k\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>), we find the set of linearly positioned normal distributions which best fit the data. It is because <span class="math notranslate nohighlight">\(\hat{y_i}\)</span> is obtained from the linear prediction equation, that the normal distributions which are fit to the data fall on a straight line.</p>
<p>Because maximizing the likelihood formula involves multiplying together probabilities, the numbers can get very small very quickly, and this can lead to computational errors. In practice, we get around this by minimizing the <em>negative log-likelihood</em>, rather than maximizing the likelihood directly. This produces the same parameter estimates, but is less prone to numerical errors. The negative log-likelihood formula is:</p>
<p><span class="math notranslate nohighlight">\( \huge \frac{n}{2} \ln(2\pi\sigma^{2}) +  \frac{{\sum\limits_{i = 1}^{n}(y_{i} - \hat{y_{i}})^{2}}}{2\sigma^{2}}\)</span></p>
<p>This formula is just the result of applying the log transformation to the likelihood formula shown earlier. It is also referred to as the <em>cost function</em>, as we want it to be <em>cheap</em> e.g. we want to find the parameter values that yield it’s minimum possible value.</p>
</section>
<section id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">#</a></h2>
<p>The python cell below defines a function which uses the negative log-likelihood formula just shown to calculate the negative log likelihood for a given set of parameters (<span class="math notranslate nohighlight">\(b_0,\)</span> <span class="math notranslate nohighlight">\(b_1\)</span>, <span class="math notranslate nohighlight">\(\sigma\)</span>) for a given dataset (a vector of outcome <span class="math notranslate nohighlight">\(y_i\)</span> values and a vector of predictor <span class="math notranslate nohighlight">\(x_i\)</span> values):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code defines a function which implements the negative log-likelihood function for linear regression</span>
<span class="k">def</span> <span class="nf">lin_reg_neg_likelihood</span><span class="p">(</span><span class="n">intercept_slope_sigma</span><span class="p">,</span> <span class="n">predictor</span><span class="p">,</span> <span class="n">outcome</span><span class="p">):</span>
  
    <span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">intercept_slope_sigma</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">intercept_slope_sigma</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">intercept_slope_sigma</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">predictor</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">outcome</span>

    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="n">output</span> <span class="o">=</span>  <span class="n">n</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<p>The python cell below tests the the negative log likelihood function with the parameters:</p>
<p><span class="math notranslate nohighlight">\(b_0\)</span> = 1</p>
<p><span class="math notranslate nohighlight">\(b_1\)</span> = 1</p>
<p><span class="math notranslate nohighlight">\(\sigma\)</span> = 1</p>
<p>for the <code class="docutils literal notranslate"><span class="pre">prestige</span> <span class="pre">~</span> <span class="pre">wealth</span></code> data, with <code class="docutils literal notranslate"><span class="pre">wealth</span></code> as the predictor and <code class="docutils literal notranslate"><span class="pre">prestige</span></code> as the outcome:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># testing the negative log-likelihood function defined above</span>
<span class="n">lin_reg_neg_likelihood</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;wealth&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;prestige&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>101943530.8938332
</pre></div>
</div>
</div>
</div>
<p>The maximum likelihood estimates can be found via calculus, by finding the parameter values which give the global minimum of the negative log-likelihood function. Using python, we can pass the cost function, and a set of parameters, to the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html">minimize</a> function, from the <a class="reference external" href="https://scipy.org/">SciPy</a> library to find the parameters which give the global minimum of the cost function. The <code class="docutils literal notranslate"><span class="pre">minimize</span></code> function will try various sets of parameters until it finds the parameters which give the lowest value of the function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># finding the paramter values that minimize the negative log-likelihood function</span>
<span class="n">minimize</span><span class="p">(</span><span class="n">lin_reg_neg_likelihood</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>  <span class="n">args</span> <span class="o">=</span> <span class="p">(</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;wealth&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;prestige&#39;</span><span class="p">]))</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-62.97370846,   4.00509327,  60.96547401])
</pre></div>
</div>
</div>
</div>
<p>The values in the array above are (in order) the intercept, slope and sigma value which give the lowest negative loglikelihood, and are the parameters which give the line of normal distributions which best fit the data:</p>
<p><img alt="" src="_images/GLM_normal_identity.png" /></p>
<p>(Image from: <a class="reference external" href="https://blogs.sas.com/content/iml/2015/09/10/plot-distrib-reg-model.html">https://blogs.sas.com/content/iml/2015/09/10/plot-distrib-reg-model.html</a>)</p>
<p>The graph below shows a line generated using this slope and intercept, alongside the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code generates the plot below</span>
<span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">lin_reg_neg_likelihood</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>  <span class="n">args</span> <span class="o">=</span> <span class="p">(</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;wealth&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;prestige&#39;</span><span class="p">]))</span><span class="o">.</span><span class="n">x</span>
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">plot_prestige_wealth_with_prediction</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;wealth&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;prestige&#39;</span><span class="p">],</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;wealth&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a2f23f724deb31941e0e79396bbbbe6c8b7ec7791e64324431b654bcd379f129.png" src="_images/a2f23f724deb31941e0e79396bbbbe6c8b7ec7791e64324431b654bcd379f129.png" />
</div>
</div>
<p>The cell below shows again the parameter estimates obtained from minimizing the cost function using <code class="docutils literal notranslate"><span class="pre">minimize</span></code>. The second cell below fits a linear regression with <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>, the parameter estimates are shown in the <code class="docutils literal notranslate"><span class="pre">coef</span></code> section of the regression table below the cell:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># finding the paramter values that minimize the negative log-likelihood function</span>
<span class="n">minimize</span><span class="p">(</span><span class="n">lin_reg_neg_likelihood</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>  <span class="n">args</span> <span class="o">=</span> <span class="p">(</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;wealth&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;prestige&#39;</span><span class="p">]))</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-62.97370846,   4.00509327,  60.96547401])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fitting a linear regression model using statsmodels</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;prestige ~ wealth&#39;</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># show the regression table</span>
<span class="n">mod</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>prestige</td>     <th>  R-squared:         </th> <td>   0.288</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.287</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   403.8</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 06 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>1.08e-75</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>18:51:00</td>     <th>  Log-Likelihood:    </th> <td> -5529.2</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>1.106e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>1.107e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>  -62.9928</td> <td>   33.908</td> <td>   -1.858</td> <td> 0.063</td> <td> -129.531</td> <td>    3.546</td>
</tr>
<tr>
  <th>wealth</th>    <td>    4.0052</td> <td>    0.199</td> <td>   20.096</td> <td> 0.000</td> <td>    3.614</td> <td>    4.396</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>50.454</td> <th>  Durbin-Watson:     </th> <td>   2.032</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  45.067</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.455</td> <th>  Prob(JB):          </th> <td>1.64e-10</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.498</td> <th>  Cond. No.          </th> <td>2.99e+03</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.99e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</div></div>
</div>
<p>We can see that the parameter values obtained by minimizing the negative log-likelihood function are identical to the parameter estimates we get from carrying out a linear regression using the <a class="reference external" href="https://www.statsmodels.org/stable/index.html">statsmodels</a> library.</p>
</section>
<section id="interpretation-one-predictor-model">
<h2>Interpretation (one predictor model)<a class="headerlink" href="#interpretation-one-predictor-model" title="Permalink to this headline">#</a></h2>
<p>Note: the intercept and slope are shown under the <code class="docutils literal notranslate"><span class="pre">coef</span></code> heading in the regression table above, the associated <span class="math notranslate nohighlight">\(p\)</span>-values are shown under <code class="docutils literal notranslate"><span class="pre">P&gt;|z|</span></code>.</p>
<p>The intercept value tells us the predicted value of the outcome (<code class="docutils literal notranslate"><span class="pre">prestige</span></code>) for a predictor (<code class="docutils literal notranslate"><span class="pre">wealth</span></code>) score of 0. This may or may not be a meaningful prediction, depending on the dataset and how many very low values of the predictor are actually observed (a lot of extrapolation is going on there are not many observations with low predictor scores!). The <span class="math notranslate nohighlight">\(p\)</span>-value for the intercept tells us how (un)likely it would be to obtain an intercpet of the value we obtained, if randomly sampling from a population where the true intercept was 0.</p>
<p>The slope tells us the expected in increase in the outcome for a 1 unit change in the predictor. In this case, based on this dataset, we expect a 4 unit increase in <code class="docutils literal notranslate"><span class="pre">prestige</span></code> for a 1 unit increase in <code class="docutils literal notranslate"><span class="pre">wealth</span></code>. The <span class="math notranslate nohighlight">\(p\)</span>-values for the predictor tell us how (un)likely it would be, under repeated random sampling, to observe a slope of the size we observed if the population slope was zero.</p>
</section>
<section id="linear-regression-with-multiple-predictors">
<h2>Linear Regression with multiple predictors<a class="headerlink" href="#linear-regression-with-multiple-predictors" title="Permalink to this headline">#</a></h2>
<p>In more than two dimensions, linear regression fits a (hyper)plane, rather than a line, to the data.</p>
<p>The graph below shows a hypothetical multiple regression model fit to an outcome with two continuous predictor variables. The blue surface is the linear regression model, the red dots are the hypothetical data points:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code generates the plot below</span>
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">three_D_lin_reg_plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/98f5ee64f97bd90b292750363be12d83413adb9a5a7b9141575cc076809f8cd1.png" src="_images/98f5ee64f97bd90b292750363be12d83413adb9a5a7b9141575cc076809f8cd1.png" />
</div>
</div>
<p>Generalized linear models, of which linear regression is a special case, are a flexible framework that allow for all types of predictor variable. Returning to the data from the current island, let’s say your research team is also interested in investigating whether religious group membership is also associated with <code class="docutils literal notranslate"><span class="pre">prestige</span></code>.</p>
<p>There are two major religions on the island, so membership of either can be indicated with a 0 or a 1 (<code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">=</span> <span class="pre">religion</span> <span class="pre">A</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">=</span> <span class="pre">religion</span> <span class="pre">B</span></code> or vice versa). Religious group membership was recorded during data collection, and a dataframe whcih also shows the variable <code class="docutils literal notranslate"><span class="pre">religion</span></code> is below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># show the dataframe</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>wealth</th>
      <th>religion</th>
      <th>prestige</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>181.35</td>
      <td>1</td>
      <td>641</td>
    </tr>
    <tr>
      <th>1</th>
      <td>178.62</td>
      <td>1</td>
      <td>652</td>
    </tr>
    <tr>
      <th>2</th>
      <td>176.06</td>
      <td>0</td>
      <td>689</td>
    </tr>
    <tr>
      <th>3</th>
      <td>190.41</td>
      <td>1</td>
      <td>632</td>
    </tr>
    <tr>
      <th>4</th>
      <td>166.84</td>
      <td>0</td>
      <td>635</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>995</th>
      <td>168.00</td>
      <td>1</td>
      <td>558</td>
    </tr>
    <tr>
      <th>996</th>
      <td>165.21</td>
      <td>1</td>
      <td>544</td>
    </tr>
    <tr>
      <th>997</th>
      <td>139.76</td>
      <td>0</td>
      <td>519</td>
    </tr>
    <tr>
      <th>998</th>
      <td>168.80</td>
      <td>1</td>
      <td>525</td>
    </tr>
    <tr>
      <th>999</th>
      <td>172.47</td>
      <td>0</td>
      <td>692</td>
    </tr>
  </tbody>
</table>
<p>1000 rows × 3 columns</p>
</div></div></div>
</div>
<p>The graph below shows a 2D scatterplot which depicts <code class="docutils literal notranslate"><span class="pre">wealth</span></code>, <code class="docutils literal notranslate"><span class="pre">prestige</span></code> and <code class="docutils literal notranslate"><span class="pre">religion</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code just generates the plot below</span>
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">plot_prestige_wealth_with_religion</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7901850711294d101288d403498b12e2e906524563d1fc77fe919e9b38b41371.png" src="_images/7901850711294d101288d403498b12e2e906524563d1fc77fe919e9b38b41371.png" />
</div>
</div>
<p>From graphical inspection, it does appear that the religious groups might differ in their average prestige. Because of what <a class="reference external" href="https://us.sagepub.com/en-us/nam/applied-regression-analysis-and-generalized-linear-models/book237254">John Fox</a> calls the ‘geometric trick’ of using indicator variables, we can also show the data in a 3D data-space. Because of the dummy coding (<code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">=</span> <span class="pre">religion</span> <span class="pre">A</span></code>, <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">=</span> <span class="pre">religion</span> <span class="pre">B</span></code>), all of the datapoints line up at either 0 or 1 on one of the axes, rather than being distributed all along the axis, as they are with the continuous predictor:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code generates the plot below</span>
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">three_D_prestige_wealth_religion_plot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">azim</span> <span class="o">=</span> <span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ff28791458c90df47a9983d55f61be2dcc79bcad468bd9c398c55d057acb0e99.png" src="_images/ff28791458c90df47a9983d55f61be2dcc79bcad468bd9c398c55d057acb0e99.png" />
</div>
</div>
<p>I’ll fit a regression model using <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>, and then use this 3D space to show the regression model alongside the data.</p>
<p>The regression model will mode <code class="docutils literal notranslate"><span class="pre">prestige</span></code> as a linear function of <code class="docutils literal notranslate"><span class="pre">religion</span></code> and <code class="docutils literal notranslate"><span class="pre">wealth</span></code>, so the model is - <code class="docutils literal notranslate"><span class="pre">prestige</span> <span class="pre">~</span> <span class="pre">religion</span> <span class="pre">+</span> <span class="pre">wealth</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fit a linear regression model with statsmodels</span>
<span class="n">lin_reg_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;prestige ~ religion + wealth&#39;</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># show the regression table</span>
<span class="n">lin_reg_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>prestige</td>     <th>  R-squared:         </th> <td>   0.687</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.686</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1094.</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 06 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>3.72e-252</td>
</tr>
<tr>
  <th>Time:</th>                 <td>18:51:00</td>     <th>  Log-Likelihood:    </th> <td> -5118.5</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>1.024e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   997</td>      <th>  BIC:               </th> <td>1.026e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   10.1766</td> <td>   22.590</td> <td>    0.450</td> <td> 0.652</td> <td>  -34.153</td> <td>   54.506</td>
</tr>
<tr>
  <th>religion</th>  <td>  -99.6753</td> <td>    2.797</td> <td>  -35.640</td> <td> 0.000</td> <td> -105.163</td> <td>  -94.187</td>
</tr>
<tr>
  <th>wealth</th>    <td>    3.9858</td> <td>    0.132</td> <td>   30.142</td> <td> 0.000</td> <td>    3.726</td> <td>    4.245</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>14.181</td> <th>  Durbin-Watson:     </th> <td>   2.013</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>   9.726</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.108</td> <th>  Prob(JB):          </th> <td> 0.00773</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.568</td> <th>  Cond. No.          </th> <td>3.00e+03</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  3e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</div></div>
</div>
<p>Here is the <code class="docutils literal notranslate"><span class="pre">prestige</span> <span class="pre">~</span> <span class="pre">religion</span> <span class="pre">+</span> <span class="pre">wealth</span></code> linear regression model shown in 3D dataspace, along with the raw data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code generates the plot below</span>
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">three_D_prestige_wealth_religion_plot_with_surface</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">lin_reg_model</span><span class="p">,</span> <span class="n">azim</span> <span class="o">=</span> <span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/37c1b82a0dd833fcdda9f0b9692a90a896bea371181f2a58273ff5b03654bb0f.png" src="_images/37c1b82a0dd833fcdda9f0b9692a90a896bea371181f2a58273ff5b03654bb0f.png" />
</div>
</div>
<p>The above graph shows the ‘geometric trick’ mentioned earlier: because <code class="docutils literal notranslate"><span class="pre">religion</span></code> is an indicator variable defined only at 0 or 1, all of the datapoints fall at either 0 or 1. But the regression surface covers the space between 0 and 1, this allows us to use the linear regression model with categorical predictors.</p>
</section>
<section id="interpretation-multiple-predictors">
<h2>Interpretation (multiple predictors)<a class="headerlink" href="#interpretation-multiple-predictors" title="Permalink to this headline">#</a></h2>
<p>How do we interpret the linear regression model parameter estimates, when there are multiple predictors?</p>
<p>Note: the intercept and slopes are shown under the <code class="docutils literal notranslate"><span class="pre">coef</span></code> heading in the regression table above, the associated <span class="math notranslate nohighlight">\(p\)</span>-values are shown under <code class="docutils literal notranslate"><span class="pre">P&gt;|z|</span></code>.</p>
<p>The intercept tells us the predicted score on the outcome variable for an observation whose score on all other predictors was 0. The <span class="math notranslate nohighlight">\(p\)</span>-value for the intercept tells us how (un)likely it would be to obtain an intercpet of the value we obtained, if randomly sampling from a population where the true intercept was 0.</p>
<p>The slope of each predictor tells us the predicted difference in the outcome variable scores for two hypothetical observations which differed <em>only</em> by a one unit score in that predictor. E.g. which had the same score on all other predictors. Sometimes this is referred to as <em>statistical control</em>. We might say each slope tells us the estimated change in the outcome for a 1 unit increase in that predictor, <em>controlling</em> for other predictors in the model.</p>
<p>This ‘statistical control’ interpretation of the slopes s is easy to explain via the graph above (the graph showing the linear regression surface and the datapoints). If we ‘hold <code class="docutils literal notranslate"><span class="pre">religion</span></code> constant’ by looking only at the graph where <code class="docutils literal notranslate"><span class="pre">religion</span> <span class="pre">=</span> <span class="pre">1</span></code>, then we compare points where <code class="docutils literal notranslate"><span class="pre">wealth</span></code> varies, the regression surface let’s us predict the change in <code class="docutils literal notranslate"><span class="pre">prestige</span></code> as a function of wealth, whilst ‘controlling for’ (e.g. holding constant) <code class="docutils literal notranslate"><span class="pre">religion</span></code>. Obviously, the validity of this interpretation depends on how well the <a class="reference external" href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/R/R5_Correlation-Regression/R5_Correlation-Regression4.html#:~:text=There%20are%20four%20assumptions%20associated,are%20independent%20of%20each%20other">assumptions of the linear regression model</a> are met…</p>
<p>The <span class="math notranslate nohighlight">\(p\)</span>-values for each predictor tell us how (un)likely it would be, under repeated random sampling, to observe a slope of the size we observed if the population slope was zero.</p>
</section>
<section id="statistical-interaction-in-linear-regression">
<h2>Statistical interaction in Linear Regression<a class="headerlink" href="#statistical-interaction-in-linear-regression" title="Permalink to this headline">#</a></h2>
<p>The definition of statistical interaction is: the influence of a predictor on the outcome variable depends on the value of some other predictor(s).</p>
<p>If we fit an interaction term in linear regression this involves taking the cross product of two predictors. So if the we wanted to look for an interaction between <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> we would include <span class="math notranslate nohighlight">\(x_1 * x_2\)</span> as a predictor in the model. So the model would be:</p>
<p><span class="math notranslate nohighlight">\(\large \hat{y}_i = b_0 + b_1x_{1i} + b_2x_{2i}...  + b_kx_{1i}x_{2i}  \)</span></p>
<p>Geometrically, this allows the linear regression surface to ‘bend’, so that the effect of the predictors is not constant, but depends on the value of the other predictor. This is shown on the graph below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this code generates the plot below</span>
<span class="n">islands_GLM</span><span class="o">.</span><span class="n">three_D_lin_reg_plot</span><span class="p">(</span><span class="n">interaction</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e407737b9ea1b0083c68e05d19d55ea3aaa02daa3b10c3c26cd1c8b55154302f.png" src="_images/e407737b9ea1b0083c68e05d19d55ea3aaa02daa3b10c3c26cd1c8b55154302f.png" />
</div>
</div>
<p>That’s it for linear regression from the conditional distribution/maximum likelihood perspective. You can visit another page/island via the links in the table of contents, and at the bottom of this page…</p>
<hr class="docutils" />
<p>By <a class="reference internal" href="99_about_the_author.html"><span class="doc std std-doc">pxr687</span></a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="1_generalized_linear_models.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">What are Generalized Linear Models?</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="3_poisson_regression.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Poisson Regression</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#context">
   Context
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model">
   Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameter-estimation">
   Parameter Estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementation">
   Implementation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretation-one-predictor-model">
   Interpretation (one predictor model)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression-with-multiple-predictors">
   Linear Regression with multiple predictors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretation-multiple-predictors">
   Interpretation (multiple predictors)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#statistical-interaction-in-linear-regression">
   Statistical interaction in Linear Regression
  </a>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>